#This configuration is used to limit the number of results returned from spark query execution
#To return all the results, set this to -1
carbon.spark.results.limit 1000
carbon.insert.batch.size 1000
spark.executor.heartbeatInterval 60s

#spark.master spark://sachiths-X1:7077
# ------------------------------------------------------
# SPARK PROPERTIES
# ------------------------------------------------------
# Default system properties included when running spark.
# This is useful for setting default environmental settings.
# Check http://spark.apache.org/docs/latest/configuration.html for further information

# Application (Spark Driver) Properties
# ------------------------------------------------------
spark.app.name  CarbonAnalytics
# Spark Driver will be running inside the carbon JVM. Hence the below properties are obsolete
# spark.driver.cores 1
# spark.driver.memory 512m

# Runtime Environment
# ------------------------------------------------------

# Spark UI

# Compression and Serialization
spark.serializer  org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer 256k
spark.kryoserializer.buffer.max 256m

# Execution Behavior

# Networking

# Scheduling
spark.scheduler.mode FAIR
# this property can be set to specify where hte fairscheduler.xml file is. the carbon specific
#     fairscheduler.xml is in the <DAS_HOME>/repository/conf/analytics/spark directory
# spark.scheduler.allocation.file <DAS_HOME>/repository/conf/analytics/spark/fairscheduler.xml

# Dynamic Allocation

# Security

# Encryption

# Spark Logging
# ------------------------------------------------------
# To allow event logging for spark you need to uncomment
# the line spark.eventlog.log true and set the directory in which the
# logs will be stored.

# spark.eventLog.enabled true
# spark.eventLog.dir <PATH_FOR_SPARK_EVENT_LOGS>

# YARN related configs
# ------------------------------------------------------
# spark.yarn.jar <path to the spark-core_2.10_1.4.3.wso2v1.jar>


